{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPECAST Weather Forecast Analysis - Complete Demo\n",
    "\n",
    "## Pipeline Integrated Prediction & Environmental Climate Analysis using Satellite Tracking\n",
    "\n",
    "This notebook demonstrates the complete PIPECAST workflow:\n",
    "1. **Forecast Processing** - Fetch weather data and generate Areas of Interest (AOIs)\n",
    "2. **Enhanced Analysis** - Intersect with census and watershed data\n",
    "3. **Ensemble Products** - Create probability maps from multiple forecasts\n",
    "4. **Risk Ranking** - Prioritize AOIs by population exposure\n",
    "\n",
    "### What You'll Learn\n",
    "- How to configure forecast parameters\n",
    "- Process multiple dates and thresholds\n",
    "- Generate ensemble probability products\n",
    "- Rank areas by population risk\n",
    "- Customize for your own use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install from PyPI\n",
    "!pip install pipecast-weather\n",
    "\n",
    "# Verify\n",
    "import pipecast\n",
    "print(f\"✓ PIPECAST version: {pipecast.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary packages and verify installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PIPECAST\n",
    "from pipecast import (\n",
    "    ForecastConfig,\n",
    "    ForecastProcessor,\n",
    "    EnsembleProcessor,\n",
    "    WeatherDataset\n",
    ")\n",
    "\n",
    "# Import for analysis\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verify installation\n",
    "import pipecast\n",
    "print(f\"✓ PIPECAST version: {pipecast.__version__}\")\n",
    "print(\"✓ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Quick Start - Single Day, Single Threshold\n",
    "\n",
    "Let's start simple: process one day with one threshold to understand the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure for a quick test\n",
    "config = ForecastConfig(\n",
    "    forecast_dates=[\"2025-02-04\"],  # One day\n",
    "    fxx_list=[12],                  # Just noon forecast\n",
    "    thresholds=[50],                # 50mm threshold\n",
    "    forecast_methods=[\"standard\"],  # No enhanced layers (faster)\n",
    "    weather_dataset=\"hrrr\",         # Continental US\n",
    "    use_census=False,\n",
    "    use_watershed=False,\n",
    "    clip_to_land=False,\n",
    "    output_dir=\"./demo_output/example1_quick\"\n",
    ")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Dates: {config.forecast_dates}\")\n",
    "print(f\"  Forecast hours: {config.fxx_list}\")\n",
    "print(f\"  Thresholds: {config.thresholds}\")\n",
    "print(f\"  Output: {config.output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the forecast\n",
    "processor = ForecastProcessor(config)\n",
    "results = processor.process_all_forecasts()\n",
    "\n",
    "print(\"\\n✅ Processing complete!\")\n",
    "print(f\"Results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine the generated AOIs\n",
    "aoi_files = processor.get_aoi_files()\n",
    "print(f\"Generated {len(aoi_files)} AOI files\")\n",
    "\n",
    "if len(aoi_files) > 0:\n",
    "    # Load first AOI file\n",
    "    gdf = gpd.read_file(aoi_files[0])\n",
    "    print(f\"\\nFirst AOI file: {aoi_files[0]}\")\n",
    "    print(f\"Number of AOIs: {len(gdf)}\")\n",
    "    print(f\"\\nColumns: {list(gdf.columns)}\")\n",
    "    print(f\"\\nSample data:\")\n",
    "    display(gdf.head())\n",
    "    \n",
    "    # Quick plot\n",
    "    if len(gdf) > 0:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        gdf.plot(ax=ax, column='mean_precip_mm', legend=True, cmap='Blues')\n",
    "        ax.set_title('Areas of Interest - Mean Precipitation > 50mm')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Multiple Dates and Thresholds\n",
    "\n",
    "Now let's process multiple days with multiple thresholds - this is more typical for real analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure for multiple dates and thresholds\n",
    "config = ForecastConfig(\n",
    "    forecast_dates=[\"2025-02-04\", \"2025-02-05\", \"2025-02-06\"],\n",
    "    fxx_list=[0, 12, 24],           # Morning, noon, evening\n",
    "    thresholds=[25, 50, 100],       # Light, moderate, heavy\n",
    "    forecast_methods=[\"standard\"],\n",
    "    weather_dataset=\"hrrr\",\n",
    "    use_census=False,\n",
    "    use_watershed=False,\n",
    "    output_dir=\"./demo_output/example2_multi\"\n",
    ")\n",
    "\n",
    "processor = ForecastProcessor(config)\n",
    "results = processor.process_all_forecasts()\n",
    "\n",
    "print(\"\\n✅ Processed:\")\n",
    "print(f\"  {len(config.forecast_dates)} dates\")\n",
    "print(f\"  {len(config.fxx_list)} forecast hours\")\n",
    "print(f\"  {len(config.thresholds)} thresholds\")\n",
    "print(f\"  Total combinations: {len(config.forecast_dates) * len(config.fxx_list) * len(config.thresholds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Enhanced Analysis with Census and Watershed Data\n",
    "\n",
    "This is where PIPECAST really shines - automatically intersecting forecast AOIs with census population and watershed data.\n",
    "\n",
    "**Note:** This will download ~470MB of census and watershed data on first run (cached for future use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure with enhanced layers\n",
    "config = ForecastConfig(\n",
    "    forecast_dates=[\"2025-02-04\", \"2025-02-05\"],\n",
    "    fxx_list=[0, 12, 24],\n",
    "    thresholds=[50, 100],\n",
    "    forecast_methods=[\"standard\", \"enhanced\"],  # Both modes\n",
    "    weather_dataset=\"hrrr\",\n",
    "    \n",
    "    # Enable enhanced analysis\n",
    "    use_census=True,        # Population data\n",
    "    use_watershed=True,     # Watershed data\n",
    "    clip_to_land=True,      # Remove ocean forecasts\n",
    "    \n",
    "    output_dir=\"./demo_output/example3_enhanced\"\n",
    ")\n",
    "\n",
    "print(\"Enhanced analysis enabled:\")\n",
    "print(f\"  ✓ Census population data\")\n",
    "print(f\"  ✓ Watershed data\")\n",
    "print(f\"  ✓ Land clipping\")\n",
    "print(\"\\nThis will download data on first run (~5 minutes)...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process with enhanced layers\n",
    "processor = ForecastProcessor(config)\n",
    "results = processor.process_all_forecasts()\n",
    "\n",
    "print(\"\\n✅ Enhanced processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare standard vs enhanced results\n",
    "date = config.forecast_dates[0]\n",
    "key = f\"F12_T50\"\n",
    "\n",
    "if 'standard' in results and 'enhanced' in results:\n",
    "    standard = results['standard'][date][key]\n",
    "    enhanced = results['enhanced'][date][key]\n",
    "    \n",
    "    print(f\"Results for {date}, F12, 50mm threshold:\")\n",
    "    print(\"\\nStandard:\")\n",
    "    print(f\"  AOIs: {standard['num_aois']}\")\n",
    "    print(f\"  Mean precip: {standard['mean_precip_over_aois']:.1f}mm\")\n",
    "    \n",
    "    print(\"\\nEnhanced:\")\n",
    "    print(f\"  AOIs: {enhanced['num_aois']}\")\n",
    "    print(f\"  Mean precip: {enhanced['mean_precip_over_aois']:.1f}mm\")\n",
    "    print(f\"  Population affected: {enhanced.get('census_pop_sum', 0):,}\")\n",
    "    print(f\"  Watershed area: {enhanced.get('watershed_area_sum', 0):.2f} deg²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Ensemble Probability Products\n",
    "\n",
    "Create ensemble probability maps by aggregating multiple forecasts across dates and forecast hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, run a forecast with multiple members\n",
    "config = ForecastConfig(\n",
    "    forecast_dates=[\"2025-02-04\", \"2025-02-05\", \"2025-02-06\"],\n",
    "    fxx_list=[0, 6, 12, 18, 24],\n",
    "    thresholds=[5, 39, 50, 100, 255],\n",
    "    forecast_methods=[\"standard\"],\n",
    "    weather_dataset=\"hrrr\",\n",
    "    output_dir=\"./demo_output/example4_ensemble\"\n",
    ")\n",
    "\n",
    "processor = ForecastProcessor(config)\n",
    "results = processor.process_all_forecasts()\n",
    "\n",
    "print(\"\\n✅ Forecast processing complete!\")\n",
    "print(f\"Total ensemble members: {len(config.forecast_dates) * len(config.fxx_list) * len(config.thresholds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble probability maps\n",
    "ensemble = EnsembleProcessor(config.output_dir)\n",
    "prob_paths = ensemble.create_ensemble_probabilities()\n",
    "\n",
    "print(\"\\n✅ Ensemble probabilities created!\")\n",
    "print(\"\\nProbability GeoTIFFs:\")\n",
    "for label, path in prob_paths.items():\n",
    "    print(f\"  {label}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Risk Ranking by Population\n",
    "\n",
    "Rank AOIs by population exposure to prioritize disaster response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank AOIs by risk\n",
    "ranked = ensemble.rank_aois_by_probability(\n",
    "    census_gdf=processor.census_gdf,  # Use loaded census data\n",
    "    top_n=50\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Risk ranking complete!\")\n",
    "print(f\"\\nTop 10 Highest Risk AOIs:\")\n",
    "display(ranked[['file_name', 'aoi_id', 'bin', 'ensemble_count', 'mean_precip_mm', 'population_affected']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize risk distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Ensemble count distribution\n",
    "axes[0].hist(ranked['ensemble_count'], bins=20, edgecolor='black')\n",
    "axes[0].set_xlabel('Ensemble Count (Probability)')\n",
    "axes[0].set_ylabel('Number of AOIs')\n",
    "axes[0].set_title('Distribution of Ensemble Probability')\n",
    "\n",
    "# Plot 2: Population vs Precipitation\n",
    "if 'population_affected' in ranked.columns:\n",
    "    axes[1].scatter(ranked['mean_precip_mm'], ranked['population_affected'], \n",
    "                   c=ranked['ensemble_count'], cmap='RdYlBu_r', s=100, alpha=0.6)\n",
    "    axes[1].set_xlabel('Mean Precipitation (mm)')\n",
    "    axes[1].set_ylabel('Population Affected')\n",
    "    axes[1].set_title('Population Exposure vs Precipitation Intensity')\n",
    "    plt.colorbar(axes[1].collections[0], ax=axes[1], label='Ensemble Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Custom Threshold Bins (Warning Levels)\n",
    "\n",
    "Define your own warning levels to match your organization's protocols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure with custom warning levels\n",
    "config = ForecastConfig(\n",
    "    forecast_dates=[\"2025-02-04\"],\n",
    "    fxx_list=[0, 12, 24],\n",
    "    \n",
    "    # Custom thresholds matching your warning system\n",
    "    thresholds=[10, 25, 50, 75, 100],\n",
    "    \n",
    "    # Custom bins for ensemble\n",
    "    threshold_bins=[\n",
    "        (0, 10),         # Green - Advisory\n",
    "        (10, 25),        # Yellow - Watch\n",
    "        (25, 50),        # Orange - Warning\n",
    "        (50, 100),       # Red - Severe\n",
    "        (100, float('inf'))  # Purple - Extreme\n",
    "    ],\n",
    "    bin_labels=[\"Advisory\", \"Watch\", \"Warning\", \"Severe\", \"Extreme\"],\n",
    "    \n",
    "    weather_dataset=\"hrrr\",\n",
    "    output_dir=\"./demo_output/example6_custom_bins\"\n",
    ")\n",
    "\n",
    "print(\"Custom Warning Levels:\")\n",
    "for label, (low, high) in zip(config.bin_labels, config.threshold_bins):\n",
    "    print(f\"  {label:10s}: {low:3.0f} - {high if high != float('inf') else '∞':>3} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process with custom bins\n",
    "processor = ForecastProcessor(config)\n",
    "results = processor.process_all_forecasts()\n",
    "\n",
    "print(\"\\n✅ Processed with custom warning levels!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7: Alaska HRRR\n",
    "\n",
    "Process Alaska forecasts using the HRRR-Alaska dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use preset for Alaska\n",
    "from pipecast.config import PresetConfigs\n",
    "\n",
    "config = PresetConfigs.alaska_hrrr(\n",
    "    forecast_dates=[\"2025-02-04\", \"2025-02-05\"],\n",
    "    output_dir=\"./demo_output/example7_alaska\"\n",
    ")\n",
    "\n",
    "# Customize\n",
    "config.fxx_list = [0, 12, 24]\n",
    "config.thresholds = [50, 100]\n",
    "config.use_census = True\n",
    "\n",
    "print(f\"Alaska Configuration:\")\n",
    "print(f\"  Dataset: {config.weather_dataset.value}\")\n",
    "print(f\"  Dates: {config.forecast_dates}\")\n",
    "print(f\"  Enhanced: {config.use_census}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Alaska\n",
    "processor = ForecastProcessor(config)\n",
    "results = processor.process_all_forecasts()\n",
    "\n",
    "print(\"\\n✅ Alaska processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 8: Complete Operational Workflow\n",
    "\n",
    "This example shows a complete operational workflow from forecast to ranked risk assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"COMPLETE OPERATIONAL WORKFLOW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Configure\n",
    "config = ForecastConfig(\n",
    "    forecast_dates=[\"2025-02-04\", \"2025-02-05\", \"2025-02-06\"],\n",
    "    fxx_list=[0, 6, 12, 18, 24],\n",
    "    thresholds=[5, 39, 50, 100, 254, 255],\n",
    "    forecast_methods=[\"standard\", \"enhanced\"],\n",
    "    use_census=True,\n",
    "    use_watershed=True,\n",
    "    clip_to_land=True,\n",
    "    weather_dataset=\"hrrr\",\n",
    "    output_dir=\"./demo_output/example8_complete\"\n",
    ")\n",
    "\n",
    "print(\"\\n>>> Step 1: Configuration\")\n",
    "print(f\"  Dates: {len(config.forecast_dates)}\")\n",
    "print(f\"  Forecast hours: {len(config.fxx_list)}\")\n",
    "print(f\"  Thresholds: {len(config.thresholds)}\")\n",
    "print(f\"  Total forecasts: {len(config.forecast_dates) * len(config.fxx_list) * len(config.thresholds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Process forecasts\n",
    "print(\"\\n>>> Step 2: Processing forecasts...\")\n",
    "processor = ForecastProcessor(config)\n",
    "results = processor.process_all_forecasts()\n",
    "print(\"✓ Forecast processing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create ensemble products\n",
    "print(\"\\n>>> Step 3: Creating ensemble products...\")\n",
    "ensemble = EnsembleProcessor(config.output_dir)\n",
    "prob_paths = ensemble.create_ensemble_probabilities()\n",
    "print(f\"✓ Created {len(prob_paths)} probability maps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Rank by risk\n",
    "print(\"\\n>>> Step 4: Ranking AOIs by population risk...\")\n",
    "ranked = ensemble.rank_aois_by_probability(\n",
    "    census_gdf=processor.census_gdf,\n",
    "    top_n=100\n",
    ")\n",
    "print(f\"✓ Ranked {len(ranked)} AOIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OPERATIONAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nForecast Period: {config.forecast_dates[0]} to {config.forecast_dates[-1]}\")\n",
    "print(f\"Total AOI files generated: {len(processor.get_aoi_files())}\")\n",
    "print(f\"Ensemble probability maps: {len(prob_paths)}\")\n",
    "\n",
    "if 'population_affected' in ranked.columns:\n",
    "    total_pop = ranked['population_affected'].sum()\n",
    "    print(f\"\\nTotal population in high-risk areas: {total_pop:,}\")\n",
    "    print(f\"\\nTop 5 Highest Risk Areas:\")\n",
    "    display(ranked[['file_name', 'bin', 'ensemble_count', 'mean_precip_mm', 'population_affected']].head(5))\n",
    "else:\n",
    "    print(f\"\\nTop 5 Areas by Ensemble Probability:\")\n",
    "    display(ranked[['file_name', 'bin', 'ensemble_count', 'mean_precip_mm']].head(5))\n",
    "\n",
    "print(f\"\\nOutputs saved to: {config.output_dir}\")\n",
    "print(\"\\n✅ WORKFLOW COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've now learned how to:\n",
    "\n",
    "✅ **Configure forecasts** with dates, thresholds, and datasets  \n",
    "✅ **Process weather data** to generate AOIs  \n",
    "✅ **Enable enhanced analysis** with census and watershed data  \n",
    "✅ **Create ensemble products** from multiple forecasts  \n",
    "✅ **Rank by risk** to prioritize response  \n",
    "✅ **Customize** for your specific use case  \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Try with your own dates** - Use recent dates for current conditions\n",
    "2. **Adjust thresholds** - Match your organization's warning levels\n",
    "3. **Add custom layers** - Include pipelines, infrastructure, etc.\n",
    "4. **Automate** - Run regularly for operational forecasting\n",
    "5. **Integrate** - Use outputs in your GIS or analysis workflows\n",
    "\n",
    "## Documentation\n",
    "\n",
    "- **README.md** - Complete package documentation\n",
    "- **QUICKSTART_COLAB.md** - Google Colab guide\n",
    "- **examples/complete_example.py** - All examples in one script\n",
    "\n",
    "## Support\n",
    "\n",
    "- GitHub Issues: [Report problems](https://github.com/NASA-EarthRISE/PIPECAST/issues)\n",
    "- Documentation: Check README.md for detailed information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
